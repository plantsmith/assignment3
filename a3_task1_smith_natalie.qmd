---
title: "Palmetto binary logistic regression (individual)"
author: "Natalie Smith"
format: 
  html:
    code-fold: true
    toc: true
    number-sections: true
    embed-resources: true
theme: Yeti
editor: visual
execute:
  echo: true
  message: false
  warning: false
---

# Overview:

The Florida palmetto data examines the survival, growth, and biomass estimates of two dominant palmetto species, *Serenoa repens* and *Sabal etonia*, in south-central Florida from 1981 to 2017, recorded at 5-year intervals. The dataset encompasses various variables, but for this analysis, we aim to focus on plant height, canopy length, canopy width, and green leaves. We'll create two different models with these variables to predict the plant species and determine which model is a better fit. Additionally, based on the superior model, we'll evaluate its success in correctly classifying a plant.

::: image-grid
![Sabal etonia](misc/sabal_etonia_2.jpeg){alt="Sabal etonia"} <img src="misc/serenoa_repens.jpeg" alt="Serenoa repens" style="width: 45%;"/>

Left: *Sabal etonia*, Right: *Serenoa repens*
:::

The models used are as follows:

-   Model 1: The log odds of plant type using plant height, canopy length, canopy width, and green leaves as predictor variables.
-   Model 2: The log odds of plant type using plant height, canopy width, and green leaves (i.e., excluding canopy length for this model).

Note that *S. repens* = speices 1 and *S. etonia* = species 2.

Data Citation: Abrahamson, W.G. 2019. Survival, growth and biomass estimates of two dominant palmetto species of south-central Florida from 1981 - 2017, ongoing at 5-year intervals ver 1. Environmental Data Initiative. https://doi.org/10.6073/pasta/f2f96ec76fbbd4b9db431c79a770c4d5

# Exploratory Plots:

```{r}
library(tidyverse) 
library(here)
library(tidymodels) 
library(ggplot2)
library(patchwork)
library(broom)
library(kableExtra)
```

```{r}
#pull in the data
p_df <- read.csv(here("data/palmetto.csv"))

#clean data
palmetto <- p_df %>%
  select(species,height,length,width,green_lvs) %>% 
  mutate(species=as_factor(species)) %>% 
  drop_na()
```

```{r}
#Species Boxplot ~ Green Leaves
leaves_plot <- ggplot(palmetto, 
                     aes(x =as.factor(species),
                         y = green_lvs)) +
  geom_boxplot(fill = "#ADD8E6", color = "#2E75B6",
               alpha = 0.8, 
               outlier.color = "#FF5733",
               outlier.shape = 16, 
               outlier.size = 1) +  
  scale_x_discrete(labels =
                     expression(italic("S.repens"),
                                italic("S.etonia"))) + 
  labs(x = "Species", y = "Green Leaves") +
  theme_minimal() +
  theme(
    axis.title.y = element_text(size = 10),
    axis.title.x = element_text(size = 10),
    axis.text = element_text(size = 10),
    legend.position = "none"
  )
# leaves_plot
```

```{r}
#Species Boxplot ~ Canopy Height
height_plot <- ggplot(palmetto, 
                     aes(x =as.factor(species),
                         y = height)) +
  geom_boxplot(fill = "#ADD8E6", color = "#2E75B6",
               alpha = 0.8, 
               outlier.color = "#FF5733",
               outlier.shape = 16, 
               outlier.size = 1) +  
  scale_x_discrete(labels =
                     expression(italic("S.repens"),
                                italic("S.etonia"))) + 
  labs(x = "Species", y = "Canopy Height") +
  theme_minimal() +
  theme(
    axis.title.y = element_text(size = 10),
    axis.title.x = element_text(size = 10),
    axis.text = element_text(size = 10),
    legend.position = "none"
  )
# height_plot
```

```{r}
#Species Boxplot ~ Canopy Length
length_plot <- ggplot(palmetto, 
                     aes(x =as.factor(species),
                         y = length)) +
  geom_boxplot(fill = "#ADD8E6", color = "#2E75B6",
               alpha = 0.8, 
               outlier.color = "#FF5733",
               outlier.shape = 16, 
               outlier.size = 1) +  
  scale_x_discrete(labels =
                     expression(italic("S.repens"),
                                italic("S.etonia"))) + 
  labs(x = "Species", y = "Canopy Length") +
  theme_minimal() +
  theme(
    axis.title.y = element_text(size = 10),
    axis.title.x = element_text(size = 10),
    axis.text = element_text(size = 10),
    legend.position = "none"
  )
# length_plot
```

```{r}
#Species Boxplot ~ Canopy Width
width_plot <- ggplot(palmetto, 
                     aes(x =as.factor(species),
                         y = width)) +
  geom_boxplot(fill = "#ADD8E6", color = "#2E75B6",
               alpha = 0.8, 
               outlier.color = "#FF5733",
               outlier.shape = 16, 
               outlier.size = 1) +  
  scale_x_discrete(labels =
                     expression(italic("S.repens"),
                                italic("S.etonia"))) + 
  labs(x = "Species", y = "Canopy Width") +
  theme_minimal() +
  theme(
    axis.title.y = element_text(size = 10),
    axis.title.x = element_text(size = 10),
    axis.text = element_text(size = 10),
    legend.position = "none"
  )
# width_plot

```

# Combine Plots:

```{r}
plot1 <- leaves_plot + 
  theme(axis.text.y = element_text(size = 8)) +
  theme(axis.title.x = element_blank())

plot2 <- height_plot +
  theme(axis.text.y = element_text(size = 8)) +
  theme(axis.title.x = element_blank())

plot3 <- length_plot +
  theme(axis.text.y = element_text(size = 8)) +
  theme(axis.title.x = element_blank())

plot4 <- width_plot +
  theme(axis.text.y = element_text(size = 8)) +
  theme(axis.title.x = element_blank())
```

While the species are very similar based on the predictor variables overall, there is slight species differentiation observed when examining "green leaves" and "canopy length."

```{r}
#| label: fig-combined_plot
#| fig-cap: 'Insert'
combinedplot <- plot1 + plot2 + plot3 + plot4
combinedplot
```

# Models:

```{r}
# Define formulas:
f1 <- species ~ height + length + width + green_lvs
f2 <- species ~ height + width + green_lvs

# BLR:
blr1 <- glm(formula = f1, data = palmetto, family = binomial)
blr2 <- glm(formula = f2, data = palmetto, family = binomial)

# Summarize:
summary(blr1)
summary(blr2)

```

COEF tell us LOG ODDS:

green leaves has largest effect on log odds. wtf is going on w height - tbd

```{r}
#Check the split:
palmetto %>%
  group_by(species) %>%
  summarize(n = n()) %>%
  ungroup() %>%
  mutate(prop = n / sum(n))

# Almost a 50/50 split - looks good. 

set.seed(123)

#Spilt into training and testing:
p_split <- initial_split(palmetto, prop = 0.80, strata = species) 

# Create Dataframes:
p_train_df <- training(p_split) 
p_test_df <- testing(p_split)

```

# if i set up a workflow below, do I have to do this step?

```{r}
#binary logistic regression model with our data

#this is the default function:
blr_mdl <- logistic_reg() %>%
  set_engine('glm')

#f1
blr_fit1 <- blr_mdl %>%
  fit(formula = f1, data = p_train_df)

#f2
blr_fit2<- blr_mdl %>%
  fit(formula = f2, data =  p_train_df)

blr_fit1
blr_fit2
```

First model is better - lower AIC

```{r}
# use our fitted model from the training set on the test set #1
p_test_predict1 <- p_test_df %>%
  mutate(predict(blr_fit1, new_data = p_test_df)) %>%
  mutate(predict(blr_fit1, new_data = ., type = 'prob'))

# use our fitted model from the training set on the test set #2
p_test_predict2 <- p_test_df %>%
  mutate(predict(blr_fit2, new_data = p_test_df)) %>%
  mutate(predict(blr_fit2, new_data = ., type = 'prob'))

```

```{r}
#accuracy #1
accuracy(p_test_predict1, truth = species, estimate = .pred_class)

#accuracy #2
accuracy(p_test_predict2, truth = species, estimate = .pred_class)

```

(1) accuracy binary 0.9123879\
(2) accuracy binary 0.896903

```{r}
#ROC 1
roc_df1 <- roc_curve(p_test_predict1, truth = species, .pred_1)
autoplot(roc_df1)

#ROC 2
roc_df2 <- roc_curve(p_test_predict2, truth = species, .pred_1)
autoplot(roc_df2)
```

```{r}
### Calculate area under curve - 50% is random guessing, 100% is perfect classifier
yardstick::roc_auc(p_test_predict1, truth = species, .pred_1)
yardstick::roc_auc(p_test_predict2, truth = species, .pred_1)
```

```{r}
#FOLDs: 
set.seed(10101)
p_train_folds <- vfold_cv(p_train_df, v = 10)
p_train_folds
```

Question: is this the same thing we did above?

```{r}
#workflow
blr_wf1 <- workflow() %>%  
  add_model(blr_mdl) %>%
  add_formula(f1)

blr_wf2 <- workflow() %>%  
  add_model(blr_mdl) %>%
  add_formula(f2)
 
```

```{r}
#apply to folded datasetls: 
blr_fit_folds1 <- blr_wf1 %>%
  fit_resamples(p_train_folds)

blr_fit_folds2 <- blr_wf2 %>%
  fit_resamples(p_train_folds)

blr_fit_folds1
blr_fit_folds2

# Metrics:
collect_metrics(blr_fit_folds1)

collect_metrics(blr_fit_folds2)

#ROC close to 100 means, close to a perfect classifier. 
```

# QUESTION:

what is the difference between regular accuracy and ROC?

Model 1: accuracy binary 0.9174543 10 0.0025763289 roc_auc binary 0.9732677 10 0.0008184978\
Model 2: accuracy binary 0.8997234 10 0.003419435 roc_auc binary 0.9638196 10 0.001191673

Based on AIC and ROC - we are going with Model 1 (lower AIC, highter ROC)

# Entire Data Set

Now, we train it: Train your selected model using the entire dataset, and create a finalized table (e.g., knitr::kable() and kableExtra functions) containing the binary logistic regression model results (at least coefficients, standard errors for the coefficients, and information for significance - consider using broom::tidy() to get you most of the way).

```{r}
#Run Model 1 on entire data set: 

blr_fit_full <- blr_mdl %>%
  fit(formula = f1, data = palmetto)

# blr_fit_full

```

# Create a finalized table - add caption

```{r}

# Broom::Tidy 
tidy_output <- tidy(blr_fit_full)

# Create kable table
final_table <- kable(tidy_output, align = "c") %>%
  kable_styling() 

# final_table
# 
# save_kable(final_table, file = "plots/kable_table.html")

```

How successfully this model would “classify” a plant as the correct species, using a 50% cutoff (e.g. if the probability is \>=50% that it is species A, then it would be classified as species A).

Use broom::augment() to find the probabilities (instead of log-odds) for each plant in the original dataset

```{r}
# Use broom:argument() to find prob for each plant in og data
p_test_predict_full <- augment(blr_fit_full, new_data = palmetto, type.predict = 'response')
head(p_test_predict_full)
```

then add a column for which species your model would classify that plant as (using a 50% cutoff) based on the included predictor variables.

```{r}
p_test_predict_full_cutoff <- p_test_predict_full %>%
  mutate(predicted_species = ifelse(.pred_1 > 0.5, "Species 1", "Species 2")) %>% 
  select(predicted_species, everything())

head(p_test_predict_full_cutoff)

```

# Question: WHY IS IT STILL .pred_class from the titanic lab. First mention of pred_class is in line 265, but I dont see where we name that variable? Did i create an unnecessary line - looks like .pred_class is doing this already.

finalized table showing, for each species, how many plants in the original dataset would be correctly classified and how many were incorrectly classified by the model, as well as an additional column with “% correctly classified”. Add a table caption above the table, and a 1-2 sentence conclusion paragraph after.

```{r}
library(dplyr)

# Calculate number of correctly and incorrectly classified plants
classification_summary <- p_test_predict_full_cutoff %>%
  group_by(species, predicted_species)

# % correct ?????

```
